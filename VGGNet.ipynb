{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGGNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sfu9eoveFWDt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow import keras\n",
        "from glob import glob\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = [224,224]"
      ],
      "metadata": {
        "id": "I2ROug72ForY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frGApUB0IxEA",
        "outputId": "0d6092f0-44e1-4c38-dc71-72d5eaf6df81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Datasets/data/train'\n",
        "test_path = '/content/drive/MyDrive/Datasets/data/test'"
      ],
      "metadata": {
        "id": "8O66_W1RFwZN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(input_shape = IMAGE_SIZE + [3],weights = 'imagenet',include_top = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HO_384xHnWi",
        "outputId": "b4da2ae0-afd3-431c-d6c7-7709ead2d477"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layers in vgg.layers:\n",
        "  layers.trainable = False"
      ],
      "metadata": {
        "id": "H-c73pOeIAKf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob('/content/drive/MyDrive/Datasets/data/train/*')\n",
        "print(len(folders))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR7IVPjcIH-F",
        "outputId": "4a8226f1-a02d-4ea9-9750-2387176ac3b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Flatten()(vgg.output)\n",
        "prediction = tf.keras.layers.Dense(len(folders),activation = 'softmax')(x)\n",
        "model = tf.keras.models.Model(inputs=vgg.input,outputs=prediction)"
      ],
      "metadata": {
        "id": "qwc2WvrpINbq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD7sQwyVJQdq",
        "outputId": "6b2cef8f-a2f2-4077-c2be-99880fce5320"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 100356    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,815,044\n",
            "Trainable params: 100,356\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIKCn1tDJbS-",
        "outputId": "29ae58d9-b45b-4d42-bbef-c27c43d00cf7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ],
      "metadata": {
        "id": "Vxw05FLfJxq5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ],
      "metadata": {
        "id": "4q0MLMpqJ8Qe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZzvIkIaJ9tY",
        "outputId": "ca4e54b3-9cf8-4456-ad82-f0aa9d4bc87b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 475 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nnej_ZhKAB9",
        "outputId": "2dcbe822-5f31-4330-a1ea-e34cd508e18b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 264 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "#lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "#num_epochs = 1000\n",
        "#num_batch_size = 32\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='mymodel.h5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer]\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit_generator(\n",
        "  train_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=1,\n",
        "  steps_per_epoch=5,\n",
        "  validation_steps=32,\n",
        "    callbacks=callbacks ,verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMeDqgqsKI4V",
        "outputId": "3f65b553-3aa5-4ceb-a67c-43949283b4fe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - ETA: 0s - loss: 24.8926 - accuracy: 0.4839 WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 32 batches). You may need to use the repeat() function when building your dataset.\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 10.78565, saving model to mymodel.h5\n",
            "5/5 [==============================] - 243s 54s/step - loss: 24.8926 - accuracy: 0.4839 - val_loss: 10.7857 - val_accuracy: 0.8447 - lr: 0.0100\n",
            "Training completed in time:  0:04:11.677023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gUx8AlfQKMxU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}